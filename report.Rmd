---
title: "Analyse des Données NPHA"
author: "Anastasios Tsiompanidis et Noah Kohrs"
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

# National Poll on Healthy Aging (NPHA)

## Auteurs du Projet
[Anastasios Tsiompanidis](anastasios.tsiompanidis@etu.univ-grenoble-alpes.fr)
[Noah Kohrs](noah.kohrs@etu.univ-grenoble-alpes.fr)

## 1- Motivation et Positionnement du Projet
Ce travail est basé sur le ["National Poll on Healthy Aging" (NPHA)](https://archive.ics.uci.edu/dataset/936/national+poll+on+healthy+aging+(npha)), une enquête menée auprès de personnes âgées pour évaluer leur état de santé et leurs besoins en matière de soins médicaux.

Notre analyse s'appuyera principalement sur la recherche de corrélation entre le nombre de visites chez le médecin d'un patient et ses caractéristiques exprimés par le reste des variables.

On précharge les librairies nécessaires pour l'analyse des données:
```{r, message=FALSE, warning=FALSE}
library(cluster)
library(rpart)
```

## 2- Analyse descriptive 
Une première lecture des données nous donne un aperçu des valeurs uniques pour chaque variable, ce qui nous permet de détecter d'éventuels problèmes de labellisation ou de valeurs manquantes.
```{r}
npha <- read.csv("NPHA-doctor-visits.csv")
summary(npha)
```

Comme nos valeurs sont catégorielles représentées par des chiffres, on va les remplacer par des labels pour une meilleure compréhension.

Cependant, le dataset utilisé contient plusieurs erreurs de labellisation, ce qui nous oblige à les corriger. Nous avons essayé dee faire au plus mieux pour rester cohérent avec les valeurs existantes.
```{r}
doctor_labels <- c("0-1", "2-3", "4+")
age_labels <- c("50-64", "65-80")

# On a ajouté la valeur "Very Poor" nous mêmes car il n'y avait
# pas de labelling indiqué pour la valeur 6. 
# Cela suit la logique et nous évite la présence de NA's 
health_labels <- c("Refused", "Excellent", "Very Good", "Good", "Fair", "Poor", "Very Poor")
empl_labels <- c("Refused", "Full-time", "Part-time", "Retired", "Not working")
yes_no_labels <- c("No", "Yes")
gender_labels <- c("M", "F")
medication_labels <- c("Refused", "Use regularly", "Use occasionally", "Do not use")

# Les valeurs devraient être "No" et "Yes", mais elles sont mal labellisées dans le dataset.
# Nous supposons que ces corrections sont appropriées.
sleep_labels <- c("Refused", "No", "A bit", "Yes")
race_labels <- c("Not asked", "Refused", "White", "Black", "Other", "Hispanic", "2+ Races")
```

Enfin, on utilise ces labels pour remplacer les valeurs existantes dans le dataset.

```{r}
colnames(npha)
npha$Number.of.Doctors.Visited = factor(npha$Number.of.Doctors.Visited, levels = 1:3, labels = doctor_labels, ordered = TRUE)
npha$Age = factor(npha$Age, levels = 1:2, labels = age_labels, ordered = FALSE)
npha$Physical.Health = factor(npha$Physical.Health, levels = c(-1, 1:6), labels = health_labels, ordered = TRUE)
npha$Mental.Health = factor(npha$Mental.Health, levels = c(-1, 1:6), labels = health_labels, ordered = TRUE)
npha$Dental.Health = factor(npha$Dental.Health, levels = c(-1, 1:6), labels = health_labels, ordered = TRUE)
npha$Employment = factor(npha$Employment, levels = c(-1, 1:4), labels = empl_labels, ordered = FALSE)
npha$Stress.Keeps.Patient.from.Sleeping = factor(npha$Stress.Keeps.Patient.from.Sleeping, levels = 0:1, labels = yes_no_labels, ordered = FALSE)
npha$Medication.Keeps.Patient.from.Sleeping = factor(npha$Medication.Keeps.Patient.from.Sleeping, levels = 0:1, labels = yes_no_labels, ordered = FALSE)
npha$Pain.Keeps.Patient.from.Sleeping = factor(npha$Pain.Keeps.Patient.from.Sleeping, levels = 0:1, labels = yes_no_labels, ordered = FALSE)
npha$Bathroom.Needs.Keeps.Patient.from.Sleeping = factor(npha$Bathroom.Needs.Keeps.Patient.from.Sleeping, levels = 0:1, labels = yes_no_labels, ordered = FALSE)
npha$Unknown.Keeps.Patient.from.Sleeping = factor(npha$Unknown.Keeps.Patient.from.Sleeping, levels = 0:1, labels = yes_no_labels, ordered = FALSE)
npha$Trouble.Sleeping = factor(npha$Trouble.Sleeping, levels = c(-1, 1:3), labels = sleep_labels, ordered = FALSE)
npha$Prescription.Sleep.Medication = factor(npha$Prescription.Sleep.Medication, levels = c(-1, 1:3), labels = medication_labels, ordered = FALSE)
npha$Race = factor(npha$Race, levels = 0:6, labels = race_labels, ordered = FALSE)
npha$Gender = factor(npha$Gender, levels = 1:2, labels = gender_labels, ordered = FALSE)

```
On obtient:

```{r}
summary(npha)
```

Ce resumé est bien plus parlant et nous permet de mieux comprendre les données que nous avons à disposition.

On observe par ailleurs que l'age des patients est toujours entre 65 et 80 ans, il s'agit donc d'une constante sur notre jeu de données. 
Nous allons donc écarter la variable de la suite de l'analyse car cela ne nous fournit aucune information utile et nuit la la lisibilité.

```{r}
npha <- npha[, c(1, 3:ncol(npha))]
# On vérifie que l'age a bien été supprimé.
colnames(npha)
```

Essayons d'avoir une vue d'ensemble de nos données.
```{r}
plot(npha)
```
Comme attendu, c'est indigeste en vu du nombre de variables présentes dans le jeu de données ainsi que de la présence excessive de variables catégorielles et non numériques.

On va donc essayer de voir les relations entre les variables et le nombre de visites chez le médecin.

```{r}

par(mfrow = c(2, 2))
boxplot(split(npha$Number.of.Doctors.Visited, npha$Employment), main = "Number of Doctors Visited by Employement Group")
boxplot(split(npha$Number.of.Doctors.Visited, npha$Physical.Health), main = "Number of Doctors Visited by Physical Health")
boxplot(split(npha$Number.of.Doctors.Visited, npha$Mental.Health), main = "Number of Doctors Visited by Mental Health")
boxplot(split(npha$Number.of.Doctors.Visited, npha$Dental.Health), main = "Number of Doctors Visited by Dental Health")
```

### Interprétation des boxplots
Les boxplots révèlent des tendances intéressantes mais ne montrent pas de différences marquées 
entre les groupes. On observe une légère augmentation du nombre de consultations médicales chez 
les individus ayant une moins bonne santé physique et mentale, bien que la variabilité reste 
importante. De même, ceux ayant une mauvaise santé dentaire semblent consulter plus fréquemment, 
mais l'écart entre les groupes reste modéré. Concernant l'emploi, les personnes retraitées ou 
sans emploi semblent légèrement plus enclines à consulter un médecin que celles en activité, bien 
que la différence ne soit pas significative. Globalement, ces distributions suggèrent des tendances 
faibles mais ne permettent pas d'identifier des facteurs prédictifs forts du nombre de consultations 
médicales.

## 3- Classification non supervisée :
On effectue une analyse de regroupement hiérarchique et un clustering PAM pour segmenter 
les données sans inclure la variable cible, puis on visualise les résultats de chaque méthode.
```{r}
par(mfrow = c(1, 1))
# Suppression de la variable cible (Number.of.Doctors.Visited)
npha_sans_visites <- npha[, -1]
summary(npha_sans_visites)
```

```{r}
dist_matrix <- daisy(npha_sans_visites[, -ncol(npha_sans_visites)])
hclust_result <- hclust(dist_matrix)
plot(hclust_result)
```

```{r}
pam_result <- pam(npha_sans_visites[, -ncol(npha_sans_visites)], k = 2)
plot(pam_result)
```

### Interprétation du graphique de clustering PAM
Le graphique de clustering PAM met en évidence deux groupes principaux parmi les observations. 
Cependant, la séparation entre ces clusters n'est pas nette, indiquant une certaine 
hétérogénéité au sein des groupes. L'explication de la variance à hauteur de 31,54 % suggère 
que les deux premières composantes principales ne capturent qu'une partie limitée des informations 
contenues dans les données. Cette faible variance implique que d'autres dimensions pourraient 
être nécessaires pour mieux différencier les groupes. De plus, la dispersion des points montre 
que certains individus sont proches de la frontière entre les clusters, suggérant que les variables 
choisies ne permettent pas de segmenter clairement la population analysée.

### Interprétation du Silhouette Plot
Le Silhouette Plot révèle une cohésion interne relativement faible des clusters, avec une valeur 
moyenne de 0,17. Ce score indique que de nombreuses observations se situent à la limite de leur 
groupe, ce qui traduit une séparation imparfaite entre les clusters. En particulier, le premier 
cluster présente une silhouette moyenne plus basse, ce qui signifie que ses individus sont plus 
dispersés et donc moins homogènes. À l'inverse, le second cluster semble mieux défini, bien que 
sa cohésion reste modérée. Globalement, ces résultats suggèrent que le choix du nombre de clusters 
pourrait être optimisé ou que certaines variables devraient être réévaluées pour améliorer la qualité 
de la classification.

## 4- Classification supervisée:

On commence par récuperer les indices pour chaque catégorie de la variable cible.
On a observé que bien qu'il n'y ait aucune classe extrémement rare, leur distribution n'est pas équilibrée.
On essaie donc dans un premier temps avec un échantillon de 50 observations par classe pour voir si le modèle arrive à prédire correctement les classes.
```{r}
# Ici aucun class est assez rare pour faire un max d'une classe

indices_1 <- which(npha$Number.of.Doctors.Visited == "0-1")
indices_2 <- which(npha$Number.of.Doctors.Visited == "2-3")
indices_3 <- which(npha$Number.of.Doctors.Visited == "4+")

sample_1 <- sample(indices_1, 50)
sample_2 <- sample(indices_2, 50)
sample_3 <- sample(indices_3, 50)
sub <- c(sample_1, sample_2, sample_3)
```

On vérifie ici qu'une des classes n'est pas trop sous-représentée.
```{r}
length(indices_1)
length(indices_2)
length(indices_3)
```

On entraîne un modèle de classification rpart sur un sous-ensemble de 
données et on évalue ses prédictions en comparant les résultats sur un 
jeu de test excluant ces mêmes indices.
```{r}
fit <- rpart(npha$Number.of.Doctors.Visited ~ ., data = npha, subset = sub)
fit
plot(fit)
res <- table(predict(fit, npha[-sub, ], type = "class"), npha[-sub, "Number.of.Doctors.Visited"])
res
```

On calcule le taux d'erreur du modèle en comparant les prédictions 
correctes aux résultats totaux, puis on l'affiche sous forme de pourcentage.
```{r}
err <- (1 - sum(diag(res)) / sum(res)) * 100
cat("Le taux d'erreur est de :", err, "%\n")
```

### Impact de l'équilibre des classes sur la performance du modèle

Au départ, l'entraînement du modèle a été réalisé en sélectionnant un nombre fixe 
d'observations par classe afin de garantir une répartition équilibrée entre les 
catégories. Cette approche permet d'éviter qu'une classe majoritaire domine l'apprentissage, 
ce qui pourrait biaiser les prédictions et réduire la capacité du modèle à identifier 
correctement les classes moins représentées.

Cependant, cette méthode ne reflète pas la distribution réelle des données. C'est 
pourquoi nous avons testé une seconde approche où chaque classe est échantillonnée 
selon un même pourcentage de ses observations totales. Cette méthode permet au 
modèle d'apprendre à partir d'une répartition plus représentative de la réalité, ce 
qui peut améliorer sa capacité de généralisation. Comparer ces deux approches permet 
d'évaluer si un équilibre artificiel améliore la précision ou si une répartition 
proportionnelle aux données initiales est plus pertinente.

```{r}
indices_1 <- which(npha$Number.of.Doctors.Visited == "0-1")
indices_2 <- which(npha$Number.of.Doctors.Visited == "2-3")
indices_3 <- which(npha$Number.of.Doctors.Visited == "4+")

sample_1 <- sample(indices_1, round(0.6 * length(indices_1), digits = 0))
sample_2 <- sample(indices_2, round(0.6 * length(indices_2), digits = 0))
sample_3 <- sample(indices_3, round(0.6 * length(indices_3), digits = 0))
sub <- c(sample_1, sample_2, sample_3)

fit <- rpart(npha$Number.of.Doctors.Visited ~ ., data = npha, subset = sub)
res <- table(predict(fit, npha[-sub, ], type = "class"), npha[-sub, "Number.of.Doctors.Visited"])

err <- (1 - sum(diag(res)) / sum(res)) * 100
cat("Le taux d'erreur est de :", err, "%\n")
```


Les résultats montrent que l'entraînement avec un échantillonnage proportionnel 
réduit significativement le taux d'erreur par rapport à un échantillonnage fixe. 
Toutefois, cela ne confirme pas que respecter la distribution naturelle des données permet au modèle 
de mieux généraliser car étant donné que le taux d'erreur reste très élevé, il est très probable que cette baisse soit en fait due à une 
sur-représentation des classes majoritaires dans l'échantillon d'entraînement, ce qui entraine une baisse artificielle du taux d'erreur en biaisant le modèle.

## Conclusion:

Les résultats de l'étude montrent que les variables analysées nee semblent pas expliquer
le nombre de consultations médicales des personnes âgées. Les tentatives 
de classification ont révélé une segmentation peu claire des groupes, avec une 
faible cohésion interne et un fort chevauchement entre les observations.

L'analyse des clusters a indiqué une variance expliquée limitée (31,54 %) et un 
score de silhouette faible (0,17), suggérant une séparation imparfaite des 
groupes. Les individus ne se distinguent pas nettement en fonction des variables étudiées, 
ce qui remet en question leur pertinence pour la prédiction du comportement médical.

De plus, le modèle supervisé testé a affiché un taux d'erreur élevé (66.13475 % / 51.92982 %), confirmant 
la difficulté à établir une relation fiable entre les caractéristiques des patients et 
leur fréquence de consultation. Aucune variable ne semble exercer une influence prédictive 
suffisante pour permettre une classification efficace. Additionnellement, le fait qu'un données d'entrainement 
propotionnelles, le taux d'erreur soit proche de 2/3 semble souligner d'autant plus une totale absence de lien, 
car c'est ce qu'on pourrait esperer en cas de prédiction strictement aléatoire.

En conclusion, les résultats indiquent que les données disponibles ne sont pas assez 
discriminantes pour prédire avec précision le nombre de visites médicales. Des variables 
supplémentaires ou une approche différente seraient nécessaires pour améliorer la capacité 
prédictive des modèles.